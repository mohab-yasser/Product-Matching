{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd84033a-2398-4880-9d45-a0cd219a826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ 'Product_Matching_Results.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "df_master = pd.read_excel(\"Product Matching Dataset.xlsx\")\n",
    "df_seller = pd.read_excel(\"Product Matching Dataset2.xlsx\")\n",
    "\n",
    "# 2ï¸âƒ£ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù„Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©)\n",
    "df_seller[\"seller_item_name_clean\"] = df_seller[\"seller_item_name\"].str.strip().str.lower()\n",
    "df_master[\"product_name_ar_clean\"] = df_master[\"product_name_ar\"].str.strip().str.lower()\n",
    "\n",
    "# 3ï¸âƒ£ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¥Ù„Ù‰ Ù‚ÙˆØ§Ø¦Ù… Ù†ØµÙˆØµ\n",
    "seller_names = df_seller[\"seller_item_name_clean\"].fillna(\"\").astype(str).tolist()\n",
    "master_names = df_master[\"product_name_ar_clean\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# 4ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ TF-IDF Vectorizer (ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… n-grams)\n",
    "vectorizer = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(2, 4), max_features=5000)\n",
    "\n",
    "# 5ï¸âƒ£ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© Ø±Ù‚Ù…ÙŠØ©\n",
    "tfidf_matrix_seller = vectorizer.fit_transform(seller_names)\n",
    "tfidf_matrix_master = vectorizer.transform(master_names)\n",
    "\n",
    "# 6ï¸âƒ£ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª ØµØºÙŠØ±Ø© Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n",
    "batch_size = 1000\n",
    "num_batches = int(np.ceil(len(df_seller) / batch_size))\n",
    "batch_results = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_seller_names = seller_names[start:end]\n",
    "\n",
    "    # ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø¯ÙØ¹Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© TF-IDF\n",
    "    tfidf_matrix_seller_batch = vectorizer.transform(batch_seller_names)\n",
    "\n",
    "    # Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ ÙƒÙˆØ³Ø§ÙŠÙ† ÙÙ‚Ø· Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙØ¹Ø©\n",
    "    cosine_similarities_batch = cosine_similarity(tfidf_matrix_seller_batch, tfidf_matrix_master)\n",
    "\n",
    "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙØ¶Ù„ ØªØ·Ø§Ø¨Ù‚\n",
    "    best_matches_batch = cosine_similarities_batch.argmax(axis=1)\n",
    "    best_scores_batch = cosine_similarities_batch.max(axis=1)\n",
    "\n",
    "    # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "    for j, seller_index in enumerate(range(start, end)):\n",
    "        if seller_index >= len(df_seller):\n",
    "            break  # Ù†ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ØªØ®Ø·ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª\n",
    "        \n",
    "        best_match_index = best_matches_batch[j]\n",
    "        batch_results.append((\n",
    "            df_seller.iloc[seller_index][\"sku\"], \n",
    "            df_seller.iloc[seller_index][\"seller_item_name\"], \n",
    "            df_master.iloc[best_match_index][\"sku\"], \n",
    "            df_master.iloc[best_match_index][\"product_name_ar_clean\"], \n",
    "            best_scores_batch[j]\n",
    "        ))\n",
    "\n",
    "# 7ï¸âƒ£ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ DataFrame\n",
    "optimized_matches_df = pd.DataFrame(batch_results, columns=[\"seller_sku\", \"seller_item_name\", \"matched_sku\", \"matched_name\", \"similarity_score\"])\n",
    "\n",
    "# 8ï¸âƒ£ Ø¯Ø§Ù„Ø© ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©\n",
    "def get_confidence_level(score):\n",
    "    if score >= 0.90:\n",
    "        return \"High\"\n",
    "    elif score >= 0.70:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# 9ï¸âƒ£ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµÙ†ÙŠÙ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "optimized_matches_df[\"confidence_level\"] = optimized_matches_df[\"similarity_score\"].apply(get_confidence_level)\n",
    "\n",
    "# ğŸ”Ÿ Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ù…Ù„Ù Ø¥ÙƒØ³Ù„\n",
    "output_file = \"Product_Matching_Results.xlsx\"\n",
    "optimized_matches_df.to_excel(output_file, index=False)\n",
    "print(\"\\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ 'Product_Matching_Results.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5fd84-6433-4c53-81bc-6189d0a89bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time  # Ù…ÙƒØªØ¨Ø© Ø§Ù„ÙˆÙ‚Øª Ù„Ø­Ø³Ø§Ø¨ Ø²Ù…Ù† Ø§Ù„ØªÙ†ÙÙŠØ°\n",
    "\n",
    "# Ø¨Ø¯Ø¡ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª Ù„Ø­Ø³Ø§Ø¨ Ø²Ù…Ù† Ø§Ù„ØªÙ†ÙÙŠØ°\n",
    "# start_time = time.time()\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "df_master = pd.read_excel(\"Product Matching Dataset.xlsx\")\n",
    "df_seller = pd.read_excel(\"Product Matching Dataset2.xlsx\")\n",
    "\n",
    "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ­Ù…ÙŠÙ„\n",
    "# data_load_time = time.time()\n",
    "# print(f\"ğŸ“¥ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ {data_load_time - start_time:.2f} Ø«ÙˆØ§Ù†Ù\")\n",
    "\n",
    "# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¨Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ Ø­Ø±ÙˆÙ ØµØºÙŠØ±Ø©\n",
    "df_seller[\"seller_item_name_clean\"] = df_seller[\"seller_item_name\"].str.strip().str.lower()\n",
    "df_master[\"product_name_ar_clean\"] = df_master[\"product_name_ar\"].str.strip().str.lower()\n",
    "\n",
    "# Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "# clean_data_time = time.time()\n",
    "# print(f\"ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ {clean_data_time - data_load_time:.2f} Ø«ÙˆØ§Ù†Ù\")\n",
    "\n",
    "# ØªØ­ÙˆÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¥Ù„Ù‰ Ù‚ÙˆØ§Ø¦Ù… Ù†ØµÙˆØµ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„\n",
    "seller_names = df_seller[\"seller_item_name_clean\"].fillna(\"\").astype(str).tolist()\n",
    "master_names = df_master[\"product_name_ar_clean\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ TF-IDF Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… n-grams\n",
    "vectorizer = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(2, 4), max_features=5000)\n",
    "\n",
    "# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© TF-IDF\n",
    "# tfidf_start_time = time.time()\n",
    "tfidf_matrix_seller = vectorizer.fit_transform(seller_names)\n",
    "tfidf_matrix_master = vectorizer.transform(master_names)\n",
    "\n",
    "# Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„\n",
    "# tfidf_end_time = time.time()\n",
    "# print(f\"ğŸ”¢ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ TF-IDF ØªÙ… ÙÙŠ {tfidf_end_time - clean_data_time:.2f} Ø«ÙˆØ§Ù†Ù\")\n",
    "\n",
    "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¯ÙØ¹Ø§Øª Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡\n",
    "batch_size = 1000\n",
    "num_batches = int(np.ceil(len(df_seller) / batch_size))\n",
    "batch_results = []\n",
    "\n",
    "# ØªØ³Ø¬ÙŠÙ„ ÙˆÙ‚Øª Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©\n",
    "# match_start_time = time.time()\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_seller_names = seller_names[start:end]\n",
    "\n",
    "    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¯ÙØ¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø¥Ù„Ù‰ TF-IDF\n",
    "    tfidf_matrix_seller_batch = vectorizer.transform(batch_seller_names)\n",
    "\n",
    "    # Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ ÙƒÙˆØ³Ø§ÙŠÙ† Ù„ÙƒÙ„ Ø¯ÙØ¹Ø© ÙÙ‚Ø·\n",
    "    cosine_similarities_batch = cosine_similarity(tfidf_matrix_seller_batch, tfidf_matrix_master)\n",
    "\n",
    "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙØ¶Ù„ ØªØ·Ø§Ø¨Ù‚ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    best_matches_batch = cosine_similarities_batch.argmax(axis=1)\n",
    "    best_scores_batch = cosine_similarities_batch.max(axis=1)\n",
    "\n",
    "    # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "    for j, seller_index in enumerate(range(start, end)):\n",
    "        if seller_index >= len(df_seller):\n",
    "            break  # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ØªØ®Ø·ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª\n",
    "        \n",
    "        best_match_index = best_matches_batch[j]\n",
    "        batch_results.append((\n",
    "            df_seller.iloc[seller_index][\"sku\"], \n",
    "            df_seller.iloc[seller_index][\"seller_item_name\"], \n",
    "            df_master.iloc[best_match_index][\"sku\"], \n",
    "            df_master.iloc[best_match_index][\"product_name_ar_clean\"], \n",
    "            best_scores_batch[j]\n",
    "        ))\n",
    "\n",
    "    # Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø¯Ù… Ø§Ù„ØªÙ†ÙÙŠØ° Ù„ÙƒÙ„ Ø¯ÙØ¹Ø©\n",
    "    # print(f\"âœ… ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯ÙØ¹Ø© {i+1}/{num_batches} ÙÙŠ {time.time() - match_start_time:.2f} Ø«ÙˆØ§Ù†Ù\")\n",
    "\n",
    "# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ DataFrame Ù„ØªØ­Ù„ÙŠÙ„Ù‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§\n",
    "optimized_matches_df = pd.DataFrame(batch_results, columns=[\"seller_sku\", \"seller_item_name\", \"matched_sku\", \"matched_name\", \"similarity_score\"])\n",
    "\n",
    "# Ø¯Ø§Ù„Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡\n",
    "def get_confidence_level(score):\n",
    "    if score >= 0.90:\n",
    "        return \"High\"\n",
    "    elif score >= 0.70:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ù„ÙƒÙ„ Ù…Ù†ØªØ¬ ØªÙ… Ù…Ø·Ø§Ø¨Ù‚ØªÙ‡\n",
    "optimized_matches_df[\"confidence_level\"] = optimized_matches_df[\"similarity_score\"].apply(get_confidence_level)\n",
    "\n",
    "# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙÙŠ Ù…Ù„Ù Ø¥ÙƒØ³Ù„\n",
    "output_file = \"Product_Matching_Results.xlsx\"\n",
    "optimized_matches_df.to_excel(output_file, index=False)\n",
    "\n",
    "# Ø¥Ù†Ù‡Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù\n",
    "# save_time = time.time()\n",
    "# print(f\"ğŸ“Š ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ {save_time - match_start_time:.2f} Ø«ÙˆØ§Ù†Ù\")\n",
    "\n",
    "# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø²Ù…Ù† Ø§Ù„ÙƒÙ„ÙŠ Ù„Ù„ØªÙ†ÙÙŠØ°\n",
    "# end_time = time.time()\n",
    "# print(f\"\\nğŸš€ Ø§Ù„Ø²Ù…Ù† Ø§Ù„ÙƒÙ„ÙŠ Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬: {end_time - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
