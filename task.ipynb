{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd84033a-2398-4880-9d45-a0cd219a826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ تم حفظ النتائج النهائية مع مستوى الثقة في 'Product_Matching_Results.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1️⃣ تحميل البيانات\n",
    "df_master = pd.read_excel(\"Product Matching Dataset.xlsx\")\n",
    "df_seller = pd.read_excel(\"Product Matching Dataset2.xlsx\")\n",
    "\n",
    "# 2️⃣ تنظيف البيانات (إزالة المسافات الزائدة وتحويل النصوص لأحرف صغيرة)\n",
    "df_seller[\"seller_item_name_clean\"] = df_seller[\"seller_item_name\"].str.strip().str.lower()\n",
    "df_master[\"product_name_ar_clean\"] = df_master[\"product_name_ar\"].str.strip().str.lower()\n",
    "\n",
    "# 3️⃣ تحويل الأسماء إلى قوائم نصوص\n",
    "seller_names = df_seller[\"seller_item_name_clean\"].fillna(\"\").astype(str).tolist()\n",
    "master_names = df_master[\"product_name_ar_clean\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# 4️⃣ إنشاء TF-IDF Vectorizer (تحليل النصوص باستخدام n-grams)\n",
    "vectorizer = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(2, 4), max_features=5000)\n",
    "\n",
    "# 5️⃣ تحويل الأسماء إلى مصفوفة رقمية\n",
    "tfidf_matrix_seller = vectorizer.fit_transform(seller_names)\n",
    "tfidf_matrix_master = vectorizer.transform(master_names)\n",
    "\n",
    "# 6️⃣ تقسيم البيانات على دفعات صغيرة لتوفير الذاكرة\n",
    "batch_size = 1000\n",
    "num_batches = int(np.ceil(len(df_seller) / batch_size))\n",
    "batch_results = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_seller_names = seller_names[start:end]\n",
    "\n",
    "    # تحويل كل دفعة إلى مصفوفة TF-IDF\n",
    "    tfidf_matrix_seller_batch = vectorizer.transform(batch_seller_names)\n",
    "\n",
    "    # حساب تشابه كوساين فقط لهذه الدفعة\n",
    "    cosine_similarities_batch = cosine_similarity(tfidf_matrix_seller_batch, tfidf_matrix_master)\n",
    "\n",
    "    # استخراج أفضل تطابق\n",
    "    best_matches_batch = cosine_similarities_batch.argmax(axis=1)\n",
    "    best_scores_batch = cosine_similarities_batch.max(axis=1)\n",
    "\n",
    "    # تخزين النتائج\n",
    "    for j, seller_index in enumerate(range(start, end)):\n",
    "        if seller_index >= len(df_seller):\n",
    "            break  # نتأكد من عدم تخطي عدد المنتجات\n",
    "        \n",
    "        best_match_index = best_matches_batch[j]\n",
    "        batch_results.append((\n",
    "            df_seller.iloc[seller_index][\"sku\"], \n",
    "            df_seller.iloc[seller_index][\"seller_item_name\"], \n",
    "            df_master.iloc[best_match_index][\"sku\"], \n",
    "            df_master.iloc[best_match_index][\"product_name_ar_clean\"], \n",
    "            best_scores_batch[j]\n",
    "        ))\n",
    "\n",
    "# 7️⃣ تحويل النتائج إلى DataFrame\n",
    "optimized_matches_df = pd.DataFrame(batch_results, columns=[\"seller_sku\", \"seller_item_name\", \"matched_sku\", \"matched_name\", \"similarity_score\"])\n",
    "\n",
    "# 8️⃣ دالة تصنيف مستوى الثقة\n",
    "def get_confidence_level(score):\n",
    "    if score >= 0.90:\n",
    "        return \"High\"\n",
    "    elif score >= 0.70:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# 9️⃣ تطبيق التصنيف على النتائج\n",
    "optimized_matches_df[\"confidence_level\"] = optimized_matches_df[\"similarity_score\"].apply(get_confidence_level)\n",
    "\n",
    "# 🔟 حفظ النتيجة في ملف إكسل\n",
    "output_file = \"Product_Matching_Results.xlsx\"\n",
    "optimized_matches_df.to_excel(output_file, index=False)\n",
    "print(\"\\n✅ تم حفظ النتائج النهائية مع مستوى الثقة في 'Product_Matching_Results.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5fd84-6433-4c53-81bc-6189d0a89bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time  # مكتبة الوقت لحساب زمن التنفيذ\n",
    "\n",
    "# بدء تسجيل الوقت لحساب زمن التنفيذ\n",
    "# start_time = time.time()\n",
    "\n",
    "# تحميل ملفات البيانات\n",
    "df_master = pd.read_excel(\"Product Matching Dataset.xlsx\")\n",
    "df_seller = pd.read_excel(\"Product Matching Dataset2.xlsx\")\n",
    "\n",
    "# التحقق من نجاح التحميل\n",
    "# data_load_time = time.time()\n",
    "# print(f\"📥 تم تحميل البيانات في {data_load_time - start_time:.2f} ثوانٍ\")\n",
    "\n",
    "# تنظيف الأسماء بإزالة المسافات الزائدة وتحويل النصوص إلى حروف صغيرة\n",
    "df_seller[\"seller_item_name_clean\"] = df_seller[\"seller_item_name\"].str.strip().str.lower()\n",
    "df_master[\"product_name_ar_clean\"] = df_master[\"product_name_ar\"].str.strip().str.lower()\n",
    "\n",
    "# انتهاء عملية تنظيف البيانات\n",
    "# clean_data_time = time.time()\n",
    "# print(f\"🧹 تم تنظيف البيانات في {clean_data_time - data_load_time:.2f} ثوانٍ\")\n",
    "\n",
    "# تحويل أسماء المنتجات إلى قوائم نصوص لاستخدامها في التحليل\n",
    "seller_names = df_seller[\"seller_item_name_clean\"].fillna(\"\").astype(str).tolist()\n",
    "master_names = df_master[\"product_name_ar_clean\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# إنشاء نموذج TF-IDF لمعالجة النصوص باستخدام n-grams\n",
    "vectorizer = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(2, 4), max_features=5000)\n",
    "\n",
    "# تحويل الأسماء إلى مصفوفة TF-IDF\n",
    "# tfidf_start_time = time.time()\n",
    "tfidf_matrix_seller = vectorizer.fit_transform(seller_names)\n",
    "tfidf_matrix_master = vectorizer.transform(master_names)\n",
    "\n",
    "# انتهاء عملية التحويل\n",
    "# tfidf_end_time = time.time()\n",
    "# print(f\"🔢 تحويل النصوص إلى TF-IDF تم في {tfidf_end_time - clean_data_time:.2f} ثوانٍ\")\n",
    "\n",
    "# تقسيم البيانات إلى دفعات لتوفير الذاكرة وتحسين الأداء\n",
    "batch_size = 1000\n",
    "num_batches = int(np.ceil(len(df_seller) / batch_size))\n",
    "batch_results = []\n",
    "\n",
    "# تسجيل وقت بدء عملية المطابقة\n",
    "# match_start_time = time.time()\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_seller_names = seller_names[start:end]\n",
    "\n",
    "    # تحويل الدفعة الحالية إلى TF-IDF\n",
    "    tfidf_matrix_seller_batch = vectorizer.transform(batch_seller_names)\n",
    "\n",
    "    # حساب تشابه كوساين لكل دفعة فقط\n",
    "    cosine_similarities_batch = cosine_similarity(tfidf_matrix_seller_batch, tfidf_matrix_master)\n",
    "\n",
    "    # استخراج أفضل تطابق من قاعدة البيانات\n",
    "    best_matches_batch = cosine_similarities_batch.argmax(axis=1)\n",
    "    best_scores_batch = cosine_similarities_batch.max(axis=1)\n",
    "\n",
    "    # تخزين النتائج\n",
    "    for j, seller_index in enumerate(range(start, end)):\n",
    "        if seller_index >= len(df_seller):\n",
    "            break  # التأكد من عدم تخطي عدد المنتجات\n",
    "        \n",
    "        best_match_index = best_matches_batch[j]\n",
    "        batch_results.append((\n",
    "            df_seller.iloc[seller_index][\"sku\"], \n",
    "            df_seller.iloc[seller_index][\"seller_item_name\"], \n",
    "            df_master.iloc[best_match_index][\"sku\"], \n",
    "            df_master.iloc[best_match_index][\"product_name_ar_clean\"], \n",
    "            best_scores_batch[j]\n",
    "        ))\n",
    "\n",
    "    # طباعة تقدم التنفيذ لكل دفعة\n",
    "    # print(f\"✅ تم تنفيذ الدفعة {i+1}/{num_batches} في {time.time() - match_start_time:.2f} ثوانٍ\")\n",
    "\n",
    "# تحويل النتائج إلى DataFrame لتحليلها لاحقًا\n",
    "optimized_matches_df = pd.DataFrame(batch_results, columns=[\"seller_sku\", \"seller_item_name\", \"matched_sku\", \"matched_name\", \"similarity_score\"])\n",
    "\n",
    "# دالة لتحديد مستوى الثقة بناءً على نسبة التشابه\n",
    "def get_confidence_level(score):\n",
    "    if score >= 0.90:\n",
    "        return \"High\"\n",
    "    elif score >= 0.70:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# تصنيف مستوى الثقة لكل منتج تم مطابقته\n",
    "optimized_matches_df[\"confidence_level\"] = optimized_matches_df[\"similarity_score\"].apply(get_confidence_level)\n",
    "\n",
    "# حفظ النتائج النهائية في ملف إكسل\n",
    "output_file = \"Product_Matching_Results.xlsx\"\n",
    "optimized_matches_df.to_excel(output_file, index=False)\n",
    "\n",
    "# إنهاء عملية حفظ الملف\n",
    "# save_time = time.time()\n",
    "# print(f\"📊 تم حفظ النتائج في {save_time - match_start_time:.2f} ثوانٍ\")\n",
    "\n",
    "# طباعة الزمن الكلي للتنفيذ\n",
    "# end_time = time.time()\n",
    "# print(f\"\\n🚀 الزمن الكلي لتنفيذ البرنامج: {end_time - start_time:.2f} ثانية\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
